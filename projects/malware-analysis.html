<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="keywords" content="Malware Analysis, Reverse Engineering, Incident Response, Static Analysis, Dynamic Analysis, CS 6262">
    <title>Malware Analysis Project - Mason Kim</title>
    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="project-details.css">
</head>
<body class="dark-theme">
    <nav class="navbar">
        <div class="nav-content">
            <a href="../index.html" class="nav-brand">Mason Kim</a>
            <div class="nav-links">
                <a href="../index.html#about">About</a>
                <a href="../index.html#experience">Experience</a>
                <a href="../index.html#projects">Projects</a>
                <a href="../index.html#contact">Contact</a>
            </div>
        </div>
    </nav>

    <main class="project-detail">
        <header class="project-header">
            <div class="container">
                <h1>Malware Analysis</h1>
                <div class="project-meta">
                    <span class="project-period">CS 6262 – Project 3</span>
                    <span class="project-status">Completed</span>
                </div>
                <div class="project-tags">
                    <span class="tech-tag">Malware Analysis</span>
                    <span class="tech-tag">Reverse Engineering</span>
                    <span class="tech-tag">Incident Response</span>
                    <span class="tech-tag">Static Analysis</span>
                    <span class="tech-tag">Dynamic Analysis</span>
                    <span class="tech-tag">Android</span>
                </div>
            </div>
        </header>

        <section class="project-content container">
            <div class="project-overview">
                <h2>Project Overview</h2>
                <p>Georgia Tech CS6262 Project&nbsp;3 dissected a three‑stage Windows malware family and an Android SMS trojan. The analysis fused static reverse engineering with controlled dynamic execution to expose <strong>C2 infrastructure, command sets, and malicious capabilities</strong>.</p>
                <p>Samples ran inside an isolated VirtualBox environment where iptables redirected all traffic to researcher‑controlled C2 emulators. Symbolic execution scripts (angr) uncovered hidden code paths, enabling full activation of dormant functionality.</p>
            </div>

            <div class="project-objectives">
                <h2>Objectives &amp; Scope</h2>
                <ul>
                    <li>Derive C2 endpoints, protocol formats, and instruction sets from opaque binaries.</li>
                    <li>Trace multi‑stage payload deployment across Windows processes and Android components.</li>
                    <li>Identify anti‑analysis and persistence techniques such as process injection and emulator checks.</li>
                    <li>Produce reproducible IOC tables and attack timelines for defenders.</li>
                </ul>
            </div>

            <div class="project-environment">
                <h2>Environment &amp; Tools</h2>
                <h3>Virtualization</h3>
                <ul>
                    <li>VirtualBox: Ubuntu host with isolated Windows&nbsp;XP and Android 4.4 guests; host‑only adapters rerouted outbound traffic to local C2 simulators.</li>
                    <li>iptables NAT rules redirected hard‑coded C2 IPs to <code>192.168.133.1</code>, e.g. <code>iptables -t nat -A PREROUTING -d 128.61.240.66 -j DNAT --to-destination 192.168.133.1</code>.</li>
                </ul>
                <pre class="mermaid">
graph LR
    Host[Host OS] -->|Host-only NIC| WinXP[Windows XP VM]
    Host -->|ADB over TCP| Android[Android VM]
    WinXP -->|HTTP| C2[Fake C2 192.168.133.1]
                </pre>
                <h3>Static Analysis</h3>
                <ul>
                    <li>Ghidra &amp; IDA Pro for disassembly, decompilation, and CFG generation.</li>
                    <li>radare2 and <code>strings</code> for API and network artifact hunting.</li>
                    <li>Custom <code>score.h</code> weighting to prioritize network-centric routines during CFG review.</li>
                    <li>Jadx/ApkTool for Android APK decompilation.</li>
                </ul>
                <h3>Dynamic Analysis</h3>
                <ul>
                    <li>Wireshark and iptables to capture and redirect HTTP traffic.</li>
                    <li>Cuckoo Sandbox and Android emulator for behavioral monitoring.</li>
                </ul>
                <h3>Specialized Utilities</h3>
                <ul>
                    <li>angr‑based symbolic execution to recover hidden command strings.</li>
                    <li><code>linux_sym_exec.py</code> harness automated command extraction across multiple functions.</li>
                    <li>Custom PHP C2 server to queue researcher‑defined instructions.</li>
                </ul>
                <pre class="mermaid">
flowchart LR
    A[Stage1.exe] --> B[Stage2.exe]
    B --> C[Payload.exe]
    C --> D{Actions}
    D -->|Exfiltration| E[Credit Card Dump]
    D -->|DDoS| F[Target List]
                </pre>
            </div>

            <div class="project-methodology">
                <h2>Methodology</h2>
                <h3>Static Reverse Engineering</h3>
                <ul>
                    <li>Enumerated API imports and suspicious strings to triage network and persistence logic.</li>
                    <li>Generated CFGs for high‑score functions and targeted them with symbolic execution.</li>
                    <li>Explored function <code>0x405190</code> with angr to recover <code>$download</code>, <code>$update</code>, and <code>$uninstall</code> tokens.</li>
                </ul>
                <h3>Dynamic Execution</h3>
                <ul>
                    <li>Injected crafted commands via the local C2 server and observed resultant system changes.</li>
                    <li>Monitored process injections and filesystem artifacts with ProcMon and Cuckoo.</li>
                </ul>
                <h3>Android Instrumentation</h3>
                <ul>
                    <li>Decompiled Smali to trace BroadcastReceiver callbacks and network routines.</li>
                    <li>Used <code>adb emu sms send</code> to trigger covert SMS commands.</li>
                </ul>
            </div>

            <div class="project-findings">
                <h2>Windows Malware: Stage Analysis</h2>
                <h3>Stage&nbsp;1 – Initial Dropper</h3>
                <ul>
                    <li>Injects into <code>iexplore.exe</code> via <code>CreateRemoteThread</code>/<code>WriteProcessMemory</code>.</li>
                    <li>C2: <code>128.61.240.66</code> (<code>netscan.gtisc.gatech.edu</code>).</li>
                    <li>Commands: <code>$download</code>, <code>$update</code>, <code>$uninstall</code>; <code>$download</code> retrieves Stage2 from <code>128.61.240.187</code>.</li>
                </ul>
                <h3>Stage&nbsp;2 – Downloader/Loader</h3>
                <ul>
                    <li>Again injects into <code>iexplore.exe</code>; contacts <code>143.215.130.19</code> (<code>canof.gtisc.gatech.edu</code>).</li>
                    <li>Obfuscated commands <code>$D0wNI0Ada5e2</code>, <code>$uPdAtea4cf</code>, <code>$Un1N5tAli</code> control payload retrieval and self‑management.</li>
                </ul>
                <h3>Stage&nbsp;3 – Payload</h3>
                <ul>
                    <li>Hides within <code>mspaint.exe</code>; C2 at <code>143.215.130.79</code> (<code>vcs.gtisc.gatech.edu/server/operate.php</code>).</li>
                    <li>Commands: <code>$connection63e6</code> (connectivity check), <code>$cardintervalcfae</code> (credit‑card exfil to <code>/drupal/read.php</code>), <code>$launchddosfc25</code> (multi‑target DDoS).</li>
                    <li>Embedded target list includes <code>web-plesk5.gatech.edu</code>, <code>netscan.gtisc.gatech.edu</code> and other academic hosts.</li>
                </ul>
                <table class="ioc-table">
                    <thead>
                        <tr><th>Stage</th><th>Injected Process</th><th>C2 Endpoint</th><th>Commands</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>Stage&nbsp;1</td><td>iexplore.exe</td><td>128.61.240.66</td><td>$download, $update, $uninstall</td></tr>
                        <tr><td>Stage&nbsp;2</td><td>iexplore.exe</td><td>143.215.130.19</td><td>$D0wNI0Ada5e2, $uPdAtea4cf, $Un1N5tAli</td></tr>
                        <tr><td>Payload</td><td>mspaint.exe</td><td>143.215.130.79</td><td>$connection63e6, $cardintervalcfae, $launchddosfc25</td></tr>
                    </tbody>
                </table>
            </div>

            <div class="project-findings">
                <h2>Android Malware: MaliciousMessenger</h2>
                <ul>
                    <li>BroadcastReceiver hijacks <code>SMS_RECEIVED</code> intents to parse covert commands.</li>
                    <li>Anti‑emulation: checks <code>TelephonyManager</code>; null implies sandbox or emulator.</li>
                    <li>Information theft: messages like “Is this Tim?” trigger HTTP exfiltration to <code>192.168.133.1:5000/reviews</code>.</li>
                    <li>Premium SMS fraud: sends texts to <code>666546</code> on attacker command.</li>
                </ul>
                <pre class="mermaid">
sequenceDiagram
    participant Attacker
    participant Phone
    participant C2
    participant Premium
    Attacker->>Phone: SMS "Is this Tim?"
    Phone->>C2: HTTP POST /reviews (device info)
    Attacker-->>Phone: SMS "pay"
    Phone->>Premium: SMS to 666546
                </pre>
            </div>

            <div class="project-findings">
                <h2>Key Indicators of Compromise</h2>
                <ul>
                    <li>C2 IPs: <code>128.61.240.66</code>, <code>128.61.240.187</code>, <code>143.215.130.19</code>, <code>143.215.130.79</code>.</li>
                    <li>Injected processes: <code>iexplore.exe</code>, <code>mspaint.exe</code>.</li>
                    <li>DDoS targets: <code>apache2-jolly.fairview.dreamhost.com</code>, <code>web-plesk5.gatech.edu</code>, <code>netscan.gtisc.gatech.edu</code>, and others.</li>
                    <li>Android premium number: <code>666546</code>.</li>
                </ul>
            </div>

            <div class="project-remediation">
                <h2>Remediation &amp; Recommendations</h2>
                <ul>
                    <li>Publish YARA/Sigma signatures for embedded command strings and hard‑coded C2 URLs; blocklist recovered endpoints and monitor for injection via Sysmon.</li>
                    <li>Instrument SMS gateways to detect covert command patterns and premium‑number abuse.</li>
                    <li>Segment analysis networks and use host‑only adapters to contain malware traffic.</li>
                </ul>
            </div>

            <div class="project-lessons">
                <h2>Challenges &amp; Lessons Learned</h2>
                <ul>
                    <li>Symbolic execution bypassed obfuscated checks but required careful state pruning to avoid path explosion.</li>
                    <li>C2‑dependent logic necessitated reliable traffic‑redirect infrastructure.</li>
                </ul>
            </div>

            <div class="project-future">
                <h2>Future Work</h2>
                <ul>
                    <li>Apply the methodology to cloud‑native malware and kernel drivers.</li>
                    <li>Automate Android command inference using differential fuzzing of BroadcastReceivers.</li>
                </ul>
            </div>

            <section id="cs6035-malware-analysis" class="section">
                <h2>CS6035 Malware Analysis Project — Behavioral Analysis & Malware Clustering</h2>

                <p class="lead">
                    This graduate project extends my prior malware work by combining <strong>dynamic sandbox analysis</strong> (Phase&nbsp;1) with <strong>machine-learning–based clustering and classification</strong> (Phase&nbsp;2). It demonstrates end-to-end skills from safe execution and behavior labeling to feature engineering, hierarchical clustering, and F1‑based evaluation.
                </p>

                <h3>Overview of the Two-Phase Structure</h3>
                <p>
                    In <strong>Phase 1</strong>, I performed <em>behavioral malware analysis</em> using Joe&nbsp;Sandbox Cloud, focusing on runtime actions (file/registry modifications, network beacons, process injection). In <strong>Phase 2</strong>, I used <em>Malheur</em> to cluster thousands of sandbox behavior traces and classify new samples by family, targeting a <strong>≥ 70% F1‑score</strong> on a held‑out test set.
                </p>

                <figure class="diagram">
                    <pre class="mermaid" aria-label="Pipeline from sandboxing to machine-learning-based detection">
flowchart LR
  A[Malware Samples] --> B[Joe Sandbox Cloud<br/>(Dynamic Analysis)]
  B --> C[Detailed Behavior Reports]
  C --> D[Analyst Labels Behaviors<br/>(Phase 1)]
  C --> E[Extract API Call Sequences<br/>for ML Features]
  E --> F[Malheur Clustering<br/>(Phase 2 Training)]
  F --> G[Malheur Classification<br/>(Phase 2 Testing)]
  G --> H[Trained Model (≥70% F‑score)]
  H --> I[Classify New Malware Samples]
                    </pre>
                    <figcaption>Figure 1 — Pipeline from sandboxing to machine‑learning‑based detection.</figcaption>
                </figure>

                <h3>Phase 1 — Behavioral Malware Analysis (Joe Sandbox Cloud)</h3>
                <h4>Background & Goals</h4>
                <p>
                    Five real‑world samples were analyzed via Joe Sandbox reports to identify behaviors such as file drops, registry persistence, network communication, and potential keylogging/anti‑VM traits. The deliverable was a behavior label set per sample across ~20 categories.
                </p>

                <h4>Tools & Dataset</h4>
                <ul>
                    <li>JoeSandboxCloud reports (process/API call traces, created files, registry/network activity, signatures)</li>
                    <li>Analyst checklist for behavior questions (e.g., autostart keys, HTTP without user‑agent, keylogging attempts)</li>
                </ul>

                <h4>Methodology</h4>
                <ul>
                    <li>Read <em>Behavior/Processes</em>, <em>Created Files</em>, <em>Registry</em>, <em>Network</em>, and <em>Signatures</em> sections.</li>
                    <li>Correlate signatures (e.g., sandbox evasion, keylogger) with raw API traces for confirmation.</li>
                    <li>Count behaviors as “attempted” if invoked by any spawned process, even if OS denied them.</li>
                </ul>

                <h4>Observations & Results</h4>
                <ul>
                    <li>Multiple samples dropped executables/DLLs; registry <code>Run</code> keys used for persistence.</li>
                    <li>Network beacons included HTTP GETs with missing user‑agent; DNS lookups and socket ops observed.</li>
                    <li>Keylogging indicators via low‑level keyboard/clipboard APIs; anti‑VM/environment checks present.</li>
                </ul>

                <h4>Limitations & Challenges</h4>
                <ul>
                    <li>Information overload in long traces—relied on filtering/keyword search and sequence context.</li>
                    <li>Runtime‑only vantage point: behaviors not triggered in sandbox remain unseen.</li>
                </ul>

                <h3>Phase 2 — Malware Clustering & Classification (Malheur)</h3>
                <h4>Background & Goals</h4>
                <p>
                    Using Malheur, I clustered behavior sequences (event streams of API calls) to discover families and then classified hold‑out/test samples, targeting ≥ 0.70 F1 on the test set and zero rejected subjects (<code>classify.max_dist=1.0</code>).
                </p>

                <h4>Tools, Data & Config</h4>
                <ul>
                    <li><strong>Data:</strong> &gt;11k training feature files and a separate testing set; each file encodes a semicolon‑separated API call sequence.</li>
                    <li><strong>Labels:</strong> Ground truth via AVClass/VirusTotal family tags embedded as pseudo file extensions (e.g., <code>.dinwod</code>).</li>
                    <li><strong>Key params:</strong> <code>ngram_len</code> for sequential context; <code>classify.max_dist=1.0</code> to avoid “rejected”.</li>
                </ul>

                <h4>Methodology</h4>
                <ul>
                    <li><em>Vectorization:</em> map event sequences to n‑gram feature vectors.</li>
                    <li><em>Training:</em> hierarchical/agglomerative clustering → cluster prototypes.</li>
                    <li><em>Tuning:</em> iterate <code>ngram_len</code>/distance settings to balance precision vs. recall.</li>
                    <li><em>Testing:</em> nearest‑prototype classification on the test set; compute precision/recall/F1.</li>
                    <li><em>Subjects:</em> classify Phase‑1 samples; ensure none are rejected.</li>
                </ul>

                <figure class="diagram">
                    <pre class="mermaid" aria-label="Malheur training and classification workflow">
flowchart TD
  subgraph Training
    A["Training Feature Files<br/>(API sequences)"] --> B[Vectorization (n‑grams)]
    B --> C[Hierarchical Clustering]
    C --> D{{Clusters}}
    D --> E[Cluster Prototypes (Model)]
    D --> F([Evaluate Precision / Recall / F1])
  end
  subgraph Testing
    G["Testing Feature Files"] --> H[Vectorization]
    H --> I[Assign to Nearest Prototype]
    I --> J([Classification Results])
    J --> K([Compute F1 on Test Set])
  end
                    </pre>
                    <figcaption>Figure 2 — Malheur training/classification workflow.</figcaption>
                </figure>

                <h4>Results</h4>
                <ul>
                    <li>Achieved <strong>~0.70 F1</strong> on the test set; all subject samples classified (no “rejected”).</li>
                    <li>High‑purity clusters aligned with known families (e.g., Dinwod, Mirai‑like network behavior).</li>
                </ul>

                <h4>Limitations & Challenges</h4>
                <ul>
                    <li>Family overlap in common behaviors; need sequential context (n‑grams) to disambiguate.</li>
                    <li>High‑dimensional feature space; clustering at scale requires careful parameter choices.</li>
                    <li>Label noise from AV aggregation; interpret cluster IDs with threat‑intel cross‑checks.</li>
                </ul>

                <h3>Key Security Skills Demonstrated</h3>
                <ul class="skills">
                    <li>Sandboxed malware execution & behavior triage</li>
                    <li>Behavior labeling & indicator extraction</li>
                    <li>Feature engineering on event sequences (n‑grams)</li>
                    <li>Unsupervised learning (hierarchical clustering)</li>
                    <li>Model evaluation (precision/recall/F1)</li>
                    <li>Scripting & automation for iterative tuning</li>
                </ul>

                <p class="note">This section complements my earlier CS6262 analysis by adding a scalable, ML‑driven approach to family discovery and classification.</p>
            </section>

            <p><a href="../index.html#projects">Back to Projects</a> | <a href="#cs6035-malware-analysis">CS6035 Research Extension</a></p>
        </section>
    </main>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Mason Kim. All rights reserved.</p>
        </div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js" defer></script>
    <script defer>
        document.addEventListener('DOMContentLoaded', () => {
            if (window.mermaid) {
                mermaid.initialize({ startOnLoad: true, theme: 'dark' });
            }
        });
    </script>
</body>
</html>
